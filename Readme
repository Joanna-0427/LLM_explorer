LLM Explorer

A lightweight CLI tool for experimenting with LLM outputs and tokenization.

What it does

Generate a short completion for a prompt (OpenAI API)

Compare outputs across multiple models

Inspect tokenization (token IDs) with tiktoken

Count tokens for a given text

Run
python LLM_explorer.py


You will see a menu with options similar to:

Generate text

Compare models

Show tokenization

Count tokens

Exit

Setup
Install dependencies
pip install openai tiktoken

Set API key

macOS/Linux:

export OPENAI_API_KEY="YOUR_API_KEY"


Windows PowerShell:

setx OPENAI_API_KEY "YOUR_API_KEY"

Configuration

In LLM_explorer.py, you can change the model list used for comparison, for example:

models = ["gpt-3.5-turbo", "gpt-4o-mini"]


You can also adjust:

temperature

max_output_tokens

models list

Known Issues / Quick Fix
tiktoken fallback encoding name

If your code uses get_coding, replace it with get_encoding:

# wrong
encoding = tiktoken.get_coding("cl100k_base")

# correct
encoding = tiktoken.get_encoding("cl100k_base")

Notes

This script sends requests to OpenAI; usage may incur API costs.

Do not hardcode API keys. Use environment variables.
